{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84de0741",
   "metadata": {},
   "source": [
    "## RiskGrid - Automated Data Diagnostic Script\n",
    "### Extracts all necessary information about your dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ef92d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f16c5aef",
   "metadata": {},
   "source": [
    "# CONFIGURATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a03bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = r\"A:\\Work\\RiskGrid\\data\\raw\\chicago_crimes.csv\"\n",
    "SAMPLE_SIZE = None\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\" \" * 25 + \"RISKGRID DATA DIAGNOSTIC\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\nAnalyzing: {DATA_PATH}\")\n",
    "print(f\"Sample size: {SAMPLE_SIZE if SAMPLE_SIZE else 'Full dataset'}\")\n",
    "print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2be900f",
   "metadata": {},
   "source": [
    "# 1. LOAD DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fcb16d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n[1/7] Loading data...\")\n",
    "try:\n",
    "    df = pd.read_csv(DATA_PATH, nrows=SAMPLE_SIZE, low_memory=False)\n",
    "    print(f\"✓ Loaded {len(df):,} rows\")\n",
    "except Exception as e:\n",
    "    print(f\"✗ Error loading data: {e}\")\n",
    "    exit(1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d43f0d",
   "metadata": {},
   "source": [
    "# 2. COLUMN IDENTIFICATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e546428",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n[2/7] Identifying key columns...\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "all_columns = df.columns.tolist()\n",
    "print(f\"Total columns: {len(all_columns)}\")\n",
    "print(\"\\nAll column names:\")\n",
    "for i, col in enumerate(all_columns, 1):\n",
    "    print(f\"  {i:2d}. {col}\")\n",
    "\n",
    "# Auto-detect key columns\n",
    "date_col = None\n",
    "lat_col = None\n",
    "lon_col = None\n",
    "crime_type_col = None\n",
    "\n",
    "# Find date column\n",
    "date_keywords = ['date', 'time', 'datetime', 'occurred', 'reported']\n",
    "for col in df.columns:\n",
    "    if any(keyword in col.lower() for keyword in date_keywords):\n",
    "        date_col = col\n",
    "        break\n",
    "\n",
    "# Find latitude column\n",
    "lat_keywords = ['lat', 'latitude', 'y']\n",
    "for col in df.columns:\n",
    "    if any(keyword in col.lower() for keyword in lat_keywords):\n",
    "        if 'location' not in col.lower():\n",
    "            lat_col = col\n",
    "            break\n",
    "\n",
    "# Find longitude column\n",
    "lon_keywords = ['lon', 'long', 'longitude', 'x']\n",
    "for col in df.columns:\n",
    "    if any(keyword in col.lower() for keyword in lon_keywords):\n",
    "        if 'location' not in col.lower():\n",
    "            lon_col = col\n",
    "            break\n",
    "\n",
    "# Find crime type column\n",
    "type_keywords = ['type', 'category', 'primary', 'description', 'offense']\n",
    "for col in df.columns:\n",
    "    if any(keyword in col.lower() for keyword in type_keywords):\n",
    "        if df[col].dtype == 'object':  # Should be text\n",
    "            crime_type_col = col\n",
    "            break\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"KEY COLUMNS DETECTED:\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"  Date/Time Column : {date_col if date_col else '❌ NOT FOUND'}\")\n",
    "print(f\"  Latitude Column  : {lat_col if lat_col else '❌ NOT FOUND'}\")\n",
    "print(f\"  Longitude Column : {lon_col if lon_col else '❌ NOT FOUND'}\")\n",
    "print(f\"  Crime Type Column: {crime_type_col if crime_type_col else '❌ NOT FOUND'}\")\n",
    "print(\"=\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cfa49aa",
   "metadata": {},
   "source": [
    "# 3. DATA QUALITY ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d65723",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n[3/7] Data quality check...\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "print(f\"Total rows: {len(df):,}\")\n",
    "print(f\"\\nDataset shape: {df.shape[0]:,} rows × {df.shape[1]} columns\")\n",
    "\n",
    "print(\"\\n\\nMISSING VALUES:\")\n",
    "print(\"-\" * 80)\n",
    "missing_summary = []\n",
    "for col in df.columns:\n",
    "    missing_count = df[col].isnull().sum()\n",
    "    if missing_count > 0:\n",
    "        missing_pct = (missing_count / len(df)) * 100\n",
    "        missing_summary.append({\n",
    "            'Column': col,\n",
    "            'Missing': missing_count,\n",
    "            'Percentage': missing_pct\n",
    "        })\n",
    "\n",
    "if missing_summary:\n",
    "    missing_df = pd.DataFrame(missing_summary).sort_values('Percentage', ascending=False)\n",
    "    print(missing_df.to_string(index=False))\n",
    "else:\n",
    "    print(\"✓ No missing values found!\")\n",
    "\n",
    "# Check coordinate quality\n",
    "if lat_col and lon_col:\n",
    "    df[lat_col] = pd.to_numeric(df[lat_col], errors='coerce')\n",
    "    df[lon_col] = pd.to_numeric(df[lon_col], errors='coerce')\n",
    "    \n",
    "    valid_coords = df[[lat_col, lon_col]].dropna()\n",
    "    coord_coverage = len(valid_coords) / len(df) * 100\n",
    "    \n",
    "    print(f\"\\n\\nCOORDINATE COVERAGE:\")\n",
    "    print(\"-\" * 80)\n",
    "    print(f\"Valid coordinates: {len(valid_coords):,} / {len(df):,} ({coord_coverage:.2f}%)\")\n",
    "    \n",
    "    if len(valid_coords) > 0:\n",
    "        print(f\"\\nCoordinate ranges:\")\n",
    "        print(f\"  Latitude : {valid_coords[lat_col].min():.6f} to {valid_coords[lat_col].max():.6f}\")\n",
    "        print(f\"  Longitude: {valid_coords[lon_col].min():.6f} to {valid_coords[lon_col].max():.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "782d6ed8",
   "metadata": {},
   "source": [
    "# 4. DATE RANGE ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c234d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\\n[4/7] Date/time analysis...\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "if date_col:\n",
    "    try:\n",
    "        df[date_col] = pd.to_datetime(df[date_col], errors='coerce')\n",
    "        valid_dates = df[date_col].dropna()\n",
    "        \n",
    "        print(f\"Date column: '{date_col}'\")\n",
    "        print(f\"Valid dates: {len(valid_dates):,} / {len(df):,} ({len(valid_dates)/len(df)*100:.2f}%)\")\n",
    "        \n",
    "        if len(valid_dates) > 0:\n",
    "            print(f\"\\nDATE RANGE:\")\n",
    "            print(f\"  Earliest: {valid_dates.min()}\")\n",
    "            print(f\"  Latest  : {valid_dates.max()}\")\n",
    "            \n",
    "            time_span = (valid_dates.max() - valid_dates.min()).days\n",
    "            print(f\"  Time span: {time_span:,} days ({time_span/365.25:.1f} years)\")\n",
    "            \n",
    "            # Extract temporal features\n",
    "            df['year'] = df[date_col].dt.year\n",
    "            df['month'] = df[date_col].dt.month\n",
    "            df['hour'] = df[date_col].dt.hour\n",
    "            df['dayofweek'] = df[date_col].dt.dayofweek\n",
    "            \n",
    "            print(f\"\\nYears covered: {sorted(df['year'].dropna().unique().astype(int).tolist())}\")\n",
    "            print(f\"Total unique dates: {df[date_col].dt.date.nunique():,}\")\n",
    "    except Exception as e:\n",
    "        print(f\"✗ Error parsing dates: {e}\")\n",
    "else:\n",
    "    print(\"✗ No date column detected\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "302fb8c6",
   "metadata": {},
   "source": [
    "# 5. CRIME PATTERNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "680666de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load just 10 rows\n",
    "df = pd.read_csv(DATA_PATH, nrows=10)\n",
    "\n",
    "print(\"Columns found:\")\n",
    "print(df.columns.tolist())\n",
    "\n",
    "print(\"\\nFirst row:\")\n",
    "print(df.iloc[0])\n",
    "\n",
    "print(\"\\nPrimary Type values:\")\n",
    "print(df['Primary Type'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "705f94e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\\n[5/7] Crime pattern analysis...\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "if crime_type_col:\n",
    "    print(f\"Crime type column: '{crime_type_col}'\")\n",
    "    print(f\"Total unique crime types: {df[crime_type_col].nunique()}\")\n",
    "    \n",
    "    print(\"\\n\\nTOP 10 CRIME TYPES:\")\n",
    "    print(\"-\" * 80)\n",
    "    top_crimes = df[crime_type_col].value_counts().head(10)\n",
    "    \n",
    "    for rank, (crime, count) in enumerate(top_crimes.items(), 1):\n",
    "        pct = count / len(df) * 100\n",
    "        bar_length = int(pct * 2)  # Scale bar\n",
    "        bar = \"█\" * bar_length\n",
    "        print(f\"{rank:2d}. {crime:35s} {count:8,} ({pct:5.2f}%) {bar}\")\n",
    "    \n",
    "    print(f\"\\nOther types: {df[crime_type_col].nunique() - 10}\")\n",
    "else:\n",
    "    print(\"✗ No crime type column detected\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03404d64",
   "metadata": {},
   "source": [
    "# 6. TEMPORAL PATTERNS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bddbe008",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\\n[6/7] Temporal patterns...\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "if 'hour' in df.columns:\n",
    "    print(\"\\nINCIDENTS BY HOUR OF DAY:\")\n",
    "    hourly = df['hour'].value_counts().sort_index()\n",
    "    max_count = hourly.max()\n",
    "    \n",
    "    for hour in range(24):\n",
    "        count = hourly.get(hour, 0)\n",
    "        bar_length = int((count / max_count) * 40) if max_count > 0 else 0\n",
    "        bar = \"█\" * bar_length\n",
    "        print(f\"  {hour:02d}:00 - {count:6,} {bar}\")\n",
    "\n",
    "if 'dayofweek' in df.columns:\n",
    "    print(\"\\n\\nINCIDENTS BY DAY OF WEEK:\")\n",
    "    days = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "    weekly = df['dayofweek'].value_counts().sort_index()\n",
    "    max_count = weekly.max()\n",
    "    \n",
    "    for day_num in range(7):\n",
    "        count = weekly.get(day_num, 0)\n",
    "        bar_length = int((count / max_count) * 40) if max_count > 0 else 0\n",
    "        bar = \"█\" * bar_length\n",
    "        print(f\"  {days[day_num]:10s} - {count:6,} {bar}\")\n",
    "\n",
    "if 'month' in df.columns:\n",
    "    print(\"\\n\\nINCIDENTS BY MONTH:\")\n",
    "    months = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', \n",
    "              'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
    "    monthly = df['month'].value_counts().sort_index()\n",
    "    max_count = monthly.max()\n",
    "    \n",
    "    for month_num in range(1, 13):\n",
    "        count = monthly.get(month_num, 0)\n",
    "        bar_length = int((count / max_count) * 40) if max_count > 0 else 0\n",
    "        bar = \"█\" * bar_length\n",
    "        print(f\"  {months[month_num-1]} - {count:6,} {bar}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd7bef9a",
   "metadata": {},
   "source": [
    "# 7. SAMPLE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff16f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\\n[7/7] Sample records...\")\n",
    "print(\"-\" * 80)\n",
    "print(\"\\nFirst 3 rows of data:\")\n",
    "print(df.head(3).to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f7affc5",
   "metadata": {},
   "source": [
    "# SUMMARY REPORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db18899e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\\n\" + \"=\" * 80)\n",
    "print(\" \" * 30 + \"SUMMARY REPORT\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "summary = f\"\"\"\n",
    "Dataset: {os.path.basename(DATA_PATH)}\n",
    "Total records analyzed: {len(df):,}\n",
    "\n",
    "KEY COLUMNS:\n",
    "  • Date/Time: {date_col if date_col else '❌ NOT FOUND'}\n",
    "  • Latitude:  {lat_col if lat_col else '❌ NOT FOUND'}\n",
    "  • Longitude: {lon_col if lon_col else '❌ NOT FOUND'}\n",
    "  • Crime Type: {crime_type_col if crime_type_col else '❌ NOT FOUND'}\n",
    "\n",
    "DATA QUALITY:\n",
    "  • Valid coordinates: {len(valid_coords) if lat_col and lon_col else 'N/A':,} ({coord_coverage if lat_col and lon_col else 0:.1f}%)\n",
    "  • Date range: {valid_dates.min().date() if date_col and len(valid_dates) > 0 else 'N/A'} to {valid_dates.max().date() if date_col and len(valid_dates) > 0 else 'N/A'}\n",
    "  • Unique crime types: {df[crime_type_col].nunique() if crime_type_col else 'N/A'}\n",
    "\n",
    "TOP 3 CRIMES:\n",
    "\"\"\"\n",
    "\n",
    "if crime_type_col:\n",
    "    for i, (crime, count) in enumerate(df[crime_type_col].value_counts().head(3).items(), 1):\n",
    "        summary += f\"  {i}. {crime} ({count:,} incidents)\\n\"\n",
    "\n",
    "print(summary)\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"✓ DIAGNOSTIC COMPLETE!\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"CONFIG = {\")\n",
    "print(f\"    'date_column': '{date_col}',\")\n",
    "print(f\"    'latitude_column': '{lat_col}',\")\n",
    "print(f\"    'longitude_column': '{lon_col}',\")\n",
    "print(f\"    'crime_type_column': '{crime_type_col}',\")\n",
    "print(\"}\")\n",
    "print(\"\\nShare this output with me to proceed! 🚀\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
